{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from decouple import config\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from keras import Sequential\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = config(\"CSV_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t0</th>\n",
       "      <th>t1</th>\n",
       "      <th>t2</th>\n",
       "      <th>t3</th>\n",
       "      <th>t4</th>\n",
       "      <th>t5</th>\n",
       "      <th>t6</th>\n",
       "      <th>t7</th>\n",
       "      <th>t8</th>\n",
       "      <th>t9</th>\n",
       "      <th>...</th>\n",
       "      <th>t191</th>\n",
       "      <th>t192</th>\n",
       "      <th>t193</th>\n",
       "      <th>t194</th>\n",
       "      <th>t195</th>\n",
       "      <th>t196</th>\n",
       "      <th>t197</th>\n",
       "      <th>t198</th>\n",
       "      <th>t199</th>\n",
       "      <th>Classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>22.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>3.45</td>\n",
       "      <td>13.45</td>\n",
       "      <td>11.45</td>\n",
       "      <td>18.45</td>\n",
       "      <td>18.45</td>\n",
       "      <td>20.45</td>\n",
       "      <td>20.45</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.30</td>\n",
       "      <td>10.30</td>\n",
       "      <td>15.30</td>\n",
       "      <td>15.30</td>\n",
       "      <td>16.30</td>\n",
       "      <td>15.30</td>\n",
       "      <td>17.30</td>\n",
       "      <td>16.30</td>\n",
       "      <td>17.30</td>\n",
       "      <td>15.30</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.85</td>\n",
       "      <td>2.85</td>\n",
       "      <td>5.85</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>2.85</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>1.85</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-1.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      t0     t1     t2     t3     t4     t5     t6     t7     t8     t9  ...  \\\n",
       "0  24.00  24.00  23.00  25.00  24.00  25.00  24.00  24.00  22.00  25.00  ...   \n",
       "1  23.00  23.00  22.00  21.00  21.00  22.00  23.00  23.00  22.00  21.00  ...   \n",
       "2  -0.55  -0.55  -0.55   3.45  13.45  11.45  18.45  18.45  20.45  20.45  ...   \n",
       "3  12.30  10.30  15.30  15.30  16.30  15.30  17.30  16.30  17.30  15.30  ...   \n",
       "4  24.85   2.85   5.85  -1.15   2.85  -1.15   1.85  -1.15   0.85  -1.15  ...   \n",
       "\n",
       "   t191  t192  t193  t194  t195  t196  t197  t198  t199  Classes  \n",
       "0  1.00 -1.00  1.00 -1.00  1.00  0.00  1.00  0.00  0.00        1  \n",
       "1 -1.00  1.00  0.00  1.00 -1.00  0.00 -1.00  1.00  0.00        1  \n",
       "2 -0.55  0.45 -0.55  0.45 -0.55  0.45 -0.55  0.45 -0.55        1  \n",
       "3 -0.70  0.30 -0.70  0.30 -0.70  1.30 -0.70  1.30 -0.70        1  \n",
       "4 -0.15  0.85 -1.15 -0.15 -1.15  0.85 -0.15  0.85 -0.15        2  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(\"Classes\", axis= 1)\n",
    "target = df[\"Classes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dummies = pd.get_dummies(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "pca.fit(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(np.arange(1, 101), pca.explained_variance_)\n",
    "plt.xlabel('PCA Feature')\n",
    "plt.ylabel('Variance')\n",
    "plt.xticks(range(1, 101, 10))\n",
    "plt.xlim(0,51)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.cumsum(pca.explained_variance_ratio_), color='black')\n",
    "plt.xlim(0,100)\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.axvline(30, c='b')\n",
    "plt.axhline(0.95, c='r')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=15)\n",
    "df_pca = pca.fit_transform(df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network without PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_scaled, target_dummies,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=target_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Input(shape=(n_features,)))\n",
    "model.add(Dense(128, activation=\"tanh\", input_shape=(n_features,)))\n",
    "model.add(Dense(64, activation=\"tanh\"))\n",
    "model.add(Dense(7, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 128)               2048      \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,759\n",
      "Trainable params: 10,759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 2.1255 - accuracy: 0.1000 - val_loss: 1.6914 - val_accuracy: 0.3667\n",
      "Epoch 2/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7324 - accuracy: 0.3000 - val_loss: 1.4885 - val_accuracy: 0.5333\n",
      "Epoch 3/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4877 - accuracy: 0.4571 - val_loss: 1.3228 - val_accuracy: 0.6000\n",
      "Epoch 4/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2969 - accuracy: 0.5286 - val_loss: 1.1936 - val_accuracy: 0.7000\n",
      "Epoch 5/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1675 - accuracy: 0.5714 - val_loss: 1.1008 - val_accuracy: 0.7000\n",
      "Epoch 6/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.0683 - accuracy: 0.6857 - val_loss: 1.0266 - val_accuracy: 0.7667\n",
      "Epoch 7/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9924 - accuracy: 0.7000 - val_loss: 0.9732 - val_accuracy: 0.7667\n",
      "Epoch 8/50\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9305 - accuracy: 0.7286 - val_loss: 0.9266 - val_accuracy: 0.7667\n",
      "Epoch 9/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8707 - accuracy: 0.7286 - val_loss: 0.8898 - val_accuracy: 0.8000\n",
      "Epoch 10/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8161 - accuracy: 0.7571 - val_loss: 0.8546 - val_accuracy: 0.8333\n",
      "Epoch 11/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7603 - accuracy: 0.8143 - val_loss: 0.8142 - val_accuracy: 0.8333\n",
      "Epoch 12/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7131 - accuracy: 0.8714 - val_loss: 0.7811 - val_accuracy: 0.8333\n",
      "Epoch 13/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6669 - accuracy: 0.8857 - val_loss: 0.7515 - val_accuracy: 0.8333\n",
      "Epoch 14/50\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6304 - accuracy: 0.8714 - val_loss: 0.7202 - val_accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5982 - accuracy: 0.9000 - val_loss: 0.6891 - val_accuracy: 0.8333\n",
      "Epoch 16/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5694 - accuracy: 0.9000 - val_loss: 0.6595 - val_accuracy: 0.8333\n",
      "Epoch 17/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5392 - accuracy: 0.9143 - val_loss: 0.6350 - val_accuracy: 0.8333\n",
      "Epoch 18/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5146 - accuracy: 0.9286 - val_loss: 0.6147 - val_accuracy: 0.8333\n",
      "Epoch 19/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4895 - accuracy: 0.9286 - val_loss: 0.5951 - val_accuracy: 0.8333\n",
      "Epoch 20/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4674 - accuracy: 0.9429 - val_loss: 0.5762 - val_accuracy: 0.8667\n",
      "Epoch 21/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4458 - accuracy: 0.9429 - val_loss: 0.5619 - val_accuracy: 0.8667\n",
      "Epoch 22/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4264 - accuracy: 0.9429 - val_loss: 0.5515 - val_accuracy: 0.8667\n",
      "Epoch 23/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4109 - accuracy: 0.9429 - val_loss: 0.5422 - val_accuracy: 0.8667\n",
      "Epoch 24/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3939 - accuracy: 0.9429 - val_loss: 0.5339 - val_accuracy: 0.8667\n",
      "Epoch 25/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3763 - accuracy: 0.9429 - val_loss: 0.5259 - val_accuracy: 0.8667\n",
      "Epoch 26/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3624 - accuracy: 0.9429 - val_loss: 0.5171 - val_accuracy: 0.8667\n",
      "Epoch 27/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3482 - accuracy: 0.9429 - val_loss: 0.5081 - val_accuracy: 0.8667\n",
      "Epoch 28/50\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3355 - accuracy: 0.9429 - val_loss: 0.4965 - val_accuracy: 0.8667\n",
      "Epoch 29/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3236 - accuracy: 0.9429 - val_loss: 0.4837 - val_accuracy: 0.8667\n",
      "Epoch 30/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3138 - accuracy: 0.9429 - val_loss: 0.4711 - val_accuracy: 0.8667\n",
      "Epoch 31/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3017 - accuracy: 0.9429 - val_loss: 0.4559 - val_accuracy: 0.8667\n",
      "Epoch 32/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2921 - accuracy: 0.9429 - val_loss: 0.4427 - val_accuracy: 0.8667\n",
      "Epoch 33/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2814 - accuracy: 0.9429 - val_loss: 0.4330 - val_accuracy: 0.9000\n",
      "Epoch 34/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.2728 - accuracy: 0.9571 - val_loss: 0.4253 - val_accuracy: 0.9000\n",
      "Epoch 35/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2632 - accuracy: 0.9571 - val_loss: 0.4190 - val_accuracy: 0.9000\n",
      "Epoch 36/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2540 - accuracy: 0.9429 - val_loss: 0.4142 - val_accuracy: 0.8667\n",
      "Epoch 37/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2490 - accuracy: 0.9429 - val_loss: 0.4030 - val_accuracy: 0.9000\n",
      "Epoch 38/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2415 - accuracy: 0.9571 - val_loss: 0.3887 - val_accuracy: 0.9333\n",
      "Epoch 39/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2339 - accuracy: 0.9714 - val_loss: 0.3754 - val_accuracy: 0.9333\n",
      "Epoch 40/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2264 - accuracy: 0.9714 - val_loss: 0.3627 - val_accuracy: 0.9333\n",
      "Epoch 41/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.2192 - accuracy: 0.9714 - val_loss: 0.3485 - val_accuracy: 0.9333\n",
      "Epoch 42/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2105 - accuracy: 0.9714 - val_loss: 0.3368 - val_accuracy: 0.9333\n",
      "Epoch 43/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.2037 - accuracy: 0.9714 - val_loss: 0.3242 - val_accuracy: 0.9333\n",
      "Epoch 44/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1952 - accuracy: 0.9714 - val_loss: 0.3145 - val_accuracy: 0.9333\n",
      "Epoch 45/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1885 - accuracy: 0.9714 - val_loss: 0.3068 - val_accuracy: 0.9333\n",
      "Epoch 46/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1830 - accuracy: 0.9714 - val_loss: 0.2976 - val_accuracy: 0.9333\n",
      "Epoch 47/50\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.1776 - accuracy: 0.9714 - val_loss: 0.2889 - val_accuracy: 0.9333\n",
      "Epoch 48/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1726 - accuracy: 0.9714 - val_loss: 0.2806 - val_accuracy: 0.9333\n",
      "Epoch 49/50\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.1680 - accuracy: 0.9714 - val_loss: 0.2733 - val_accuracy: 0.9333\n",
      "Epoch 50/50\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.1635 - accuracy: 0.9714 - val_loss: 0.2677 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1602318286895752\n",
      "Train acc: 0.9714285731315613\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Train loss:\", loss)\n",
    "print(\"Train acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.2676853835582733\n",
      "Test acc: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_model_all_features.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_pca, target_dummies,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=target_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#model.add(Input(shape=(n_features,)))\n",
    "#model.add(Dropout(0.30))\n",
    "model.add(Dense(n_features, activation=\"tanh\", input_shape=(n_features,)))\n",
    "#model.add(Dense(10, activation=\"tanh\"))\n",
    "model.add(Dense(7, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 15)                240       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 7)                 112       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 352\n",
      "Trainable params: 352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 0s 64ms/step - loss: 2.5687 - accuracy: 0.1000 - val_loss: 2.3747 - val_accuracy: 0.1000\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 2.5233 - accuracy: 0.1000 - val_loss: 2.3413 - val_accuracy: 0.1000\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.4836 - accuracy: 0.1000 - val_loss: 2.3089 - val_accuracy: 0.1333\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.4476 - accuracy: 0.1143 - val_loss: 2.2782 - val_accuracy: 0.1333\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.4101 - accuracy: 0.1143 - val_loss: 2.2498 - val_accuracy: 0.1333\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.3770 - accuracy: 0.1143 - val_loss: 2.2221 - val_accuracy: 0.1333\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.3427 - accuracy: 0.1143 - val_loss: 2.1947 - val_accuracy: 0.1333\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.3092 - accuracy: 0.1143 - val_loss: 2.1667 - val_accuracy: 0.1333\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2762 - accuracy: 0.1143 - val_loss: 2.1381 - val_accuracy: 0.1333\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2435 - accuracy: 0.1143 - val_loss: 2.1105 - val_accuracy: 0.1333\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.2129 - accuracy: 0.1143 - val_loss: 2.0844 - val_accuracy: 0.1667\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1817 - accuracy: 0.1286 - val_loss: 2.0577 - val_accuracy: 0.1667\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.1514 - accuracy: 0.1286 - val_loss: 2.0311 - val_accuracy: 0.1667\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 2.1230 - accuracy: 0.1286 - val_loss: 2.0048 - val_accuracy: 0.1667\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0936 - accuracy: 0.1286 - val_loss: 1.9803 - val_accuracy: 0.1667\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0664 - accuracy: 0.1286 - val_loss: 1.9564 - val_accuracy: 0.1667\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 2.0387 - accuracy: 0.1857 - val_loss: 1.9348 - val_accuracy: 0.1667\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 2.0126 - accuracy: 0.1857 - val_loss: 1.9140 - val_accuracy: 0.2000\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9880 - accuracy: 0.1714 - val_loss: 1.8937 - val_accuracy: 0.2000\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9621 - accuracy: 0.1714 - val_loss: 1.8732 - val_accuracy: 0.2000\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.9372 - accuracy: 0.1714 - val_loss: 1.8522 - val_accuracy: 0.2333\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.9132 - accuracy: 0.2429 - val_loss: 1.8317 - val_accuracy: 0.2667\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8900 - accuracy: 0.2571 - val_loss: 1.8109 - val_accuracy: 0.3667\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.8663 - accuracy: 0.2714 - val_loss: 1.7901 - val_accuracy: 0.3667\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8432 - accuracy: 0.3000 - val_loss: 1.7700 - val_accuracy: 0.3333\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.8201 - accuracy: 0.3143 - val_loss: 1.7515 - val_accuracy: 0.3333\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7982 - accuracy: 0.3143 - val_loss: 1.7346 - val_accuracy: 0.3667\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7765 - accuracy: 0.3286 - val_loss: 1.7185 - val_accuracy: 0.4333\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 1.7562 - accuracy: 0.3571 - val_loss: 1.7027 - val_accuracy: 0.4667\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.7353 - accuracy: 0.3714 - val_loss: 1.6874 - val_accuracy: 0.4667\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.7151 - accuracy: 0.3714 - val_loss: 1.6726 - val_accuracy: 0.4333\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6953 - accuracy: 0.3571 - val_loss: 1.6585 - val_accuracy: 0.4000\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6762 - accuracy: 0.3429 - val_loss: 1.6456 - val_accuracy: 0.4000\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6583 - accuracy: 0.3571 - val_loss: 1.6335 - val_accuracy: 0.4000\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6405 - accuracy: 0.3714 - val_loss: 1.6215 - val_accuracy: 0.4000\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6232 - accuracy: 0.3714 - val_loss: 1.6099 - val_accuracy: 0.4333\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.6063 - accuracy: 0.3857 - val_loss: 1.5986 - val_accuracy: 0.4333\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.5893 - accuracy: 0.3857 - val_loss: 1.5872 - val_accuracy: 0.4333\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.5731 - accuracy: 0.3857 - val_loss: 1.5754 - val_accuracy: 0.5000\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.5576 - accuracy: 0.4143 - val_loss: 1.5641 - val_accuracy: 0.5000\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.5416 - accuracy: 0.4143 - val_loss: 1.5534 - val_accuracy: 0.5000\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.5266 - accuracy: 0.4143 - val_loss: 1.5435 - val_accuracy: 0.5333\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.5117 - accuracy: 0.4286 - val_loss: 1.5344 - val_accuracy: 0.5333\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4977 - accuracy: 0.4286 - val_loss: 1.5254 - val_accuracy: 0.5333\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4832 - accuracy: 0.4286 - val_loss: 1.5162 - val_accuracy: 0.5333\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4692 - accuracy: 0.4286 - val_loss: 1.5075 - val_accuracy: 0.5333\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.4560 - accuracy: 0.4286 - val_loss: 1.4987 - val_accuracy: 0.5333\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4425 - accuracy: 0.4429 - val_loss: 1.4901 - val_accuracy: 0.5333\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.4301 - accuracy: 0.4571 - val_loss: 1.4816 - val_accuracy: 0.5333\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 1.4169 - accuracy: 0.4571 - val_loss: 1.4730 - val_accuracy: 0.5333\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.4048 - accuracy: 0.5143 - val_loss: 1.4644 - val_accuracy: 0.5333\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3929 - accuracy: 0.5143 - val_loss: 1.4563 - val_accuracy: 0.5333\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.3814 - accuracy: 0.5143 - val_loss: 1.4479 - val_accuracy: 0.5333\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3701 - accuracy: 0.5143 - val_loss: 1.4390 - val_accuracy: 0.5333\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.3584 - accuracy: 0.5429 - val_loss: 1.4305 - val_accuracy: 0.5333\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3469 - accuracy: 0.5429 - val_loss: 1.4207 - val_accuracy: 0.5333\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.3359 - accuracy: 0.5429 - val_loss: 1.4106 - val_accuracy: 0.5667\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3251 - accuracy: 0.5571 - val_loss: 1.4008 - val_accuracy: 0.5667\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3140 - accuracy: 0.5571 - val_loss: 1.3915 - val_accuracy: 0.5667\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.3037 - accuracy: 0.5571 - val_loss: 1.3824 - val_accuracy: 0.5667\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2940 - accuracy: 0.5571 - val_loss: 1.3735 - val_accuracy: 0.5667\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2833 - accuracy: 0.5857 - val_loss: 1.3648 - val_accuracy: 0.5667\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2729 - accuracy: 0.5857 - val_loss: 1.3567 - val_accuracy: 0.5667\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2631 - accuracy: 0.5857 - val_loss: 1.3488 - val_accuracy: 0.5667\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2533 - accuracy: 0.6000 - val_loss: 1.3403 - val_accuracy: 0.5667\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.2436 - accuracy: 0.6143 - val_loss: 1.3320 - val_accuracy: 0.5667\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.2342 - accuracy: 0.6143 - val_loss: 1.3248 - val_accuracy: 0.5667\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 1.2248 - accuracy: 0.6143 - val_loss: 1.3178 - val_accuracy: 0.5667\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2160 - accuracy: 0.6143 - val_loss: 1.3115 - val_accuracy: 0.5667\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.2071 - accuracy: 0.6143 - val_loss: 1.3049 - val_accuracy: 0.5667\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1985 - accuracy: 0.6143 - val_loss: 1.2978 - val_accuracy: 0.5667\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1895 - accuracy: 0.6143 - val_loss: 1.2905 - val_accuracy: 0.5667\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1808 - accuracy: 0.6143 - val_loss: 1.2832 - val_accuracy: 0.5667\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.1718 - accuracy: 0.6143 - val_loss: 1.2758 - val_accuracy: 0.5667\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1627 - accuracy: 0.6143 - val_loss: 1.2689 - val_accuracy: 0.5667\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1534 - accuracy: 0.6143 - val_loss: 1.2623 - val_accuracy: 0.5667\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1449 - accuracy: 0.6143 - val_loss: 1.2553 - val_accuracy: 0.5667\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.1351 - accuracy: 0.6429 - val_loss: 1.2485 - val_accuracy: 0.5667\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1266 - accuracy: 0.6429 - val_loss: 1.2418 - val_accuracy: 0.5667\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1185 - accuracy: 0.6429 - val_loss: 1.2354 - val_accuracy: 0.5667\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 1.1098 - accuracy: 0.6429 - val_loss: 1.2292 - val_accuracy: 0.5667\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.1014 - accuracy: 0.6429 - val_loss: 1.2233 - val_accuracy: 0.5667\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0939 - accuracy: 0.6429 - val_loss: 1.2179 - val_accuracy: 0.5667\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0861 - accuracy: 0.6429 - val_loss: 1.2124 - val_accuracy: 0.5667\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0786 - accuracy: 0.6429 - val_loss: 1.2070 - val_accuracy: 0.5667\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 1.0712 - accuracy: 0.6429 - val_loss: 1.2018 - val_accuracy: 0.5667\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 1.0637 - accuracy: 0.6429 - val_loss: 1.1960 - val_accuracy: 0.5667\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.0564 - accuracy: 0.6429 - val_loss: 1.1900 - val_accuracy: 0.5667\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 1.0489 - accuracy: 0.6714 - val_loss: 1.1835 - val_accuracy: 0.5667\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0420 - accuracy: 0.6714 - val_loss: 1.1773 - val_accuracy: 0.5667\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0348 - accuracy: 0.6714 - val_loss: 1.1719 - val_accuracy: 0.5667\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 1.0278 - accuracy: 0.7000 - val_loss: 1.1664 - val_accuracy: 0.5667\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 1.0210 - accuracy: 0.7000 - val_loss: 1.1610 - val_accuracy: 0.5667\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 1.0140 - accuracy: 0.7000 - val_loss: 1.1563 - val_accuracy: 0.5667\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0077 - accuracy: 0.6714 - val_loss: 1.1523 - val_accuracy: 0.5667\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 1.0011 - accuracy: 0.6714 - val_loss: 1.1484 - val_accuracy: 0.5667\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.9954 - accuracy: 0.7000 - val_loss: 1.1439 - val_accuracy: 0.5667\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.9890 - accuracy: 0.7000 - val_loss: 1.1382 - val_accuracy: 0.5667\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.9827 - accuracy: 0.7000 - val_loss: 1.1325 - val_accuracy: 0.5667\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9769 - accuracy: 0.7000 - val_loss: 1.1263 - val_accuracy: 0.5667\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9708 - accuracy: 0.7143 - val_loss: 1.1201 - val_accuracy: 0.5667\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9651 - accuracy: 0.7286 - val_loss: 1.1138 - val_accuracy: 0.5667\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9591 - accuracy: 0.7286 - val_loss: 1.1083 - val_accuracy: 0.5667\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.9532 - accuracy: 0.7286 - val_loss: 1.1031 - val_accuracy: 0.5667\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.9475 - accuracy: 0.7286 - val_loss: 1.0980 - val_accuracy: 0.5667\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9418 - accuracy: 0.7286 - val_loss: 1.0931 - val_accuracy: 0.5667\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9358 - accuracy: 0.7286 - val_loss: 1.0877 - val_accuracy: 0.5667\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9302 - accuracy: 0.7286 - val_loss: 1.0824 - val_accuracy: 0.6333\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9246 - accuracy: 0.7286 - val_loss: 1.0774 - val_accuracy: 0.6333\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.9187 - accuracy: 0.7286 - val_loss: 1.0735 - val_accuracy: 0.6333\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9131 - accuracy: 0.7286 - val_loss: 1.0697 - val_accuracy: 0.6333\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9075 - accuracy: 0.7286 - val_loss: 1.0657 - val_accuracy: 0.6333\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.9023 - accuracy: 0.7286 - val_loss: 1.0610 - val_accuracy: 0.6667\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8967 - accuracy: 0.7429 - val_loss: 1.0561 - val_accuracy: 0.7000\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8912 - accuracy: 0.7571 - val_loss: 1.0513 - val_accuracy: 0.7000\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8851 - accuracy: 0.7571 - val_loss: 1.0465 - val_accuracy: 0.7000\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8792 - accuracy: 0.7571 - val_loss: 1.0415 - val_accuracy: 0.7000\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8739 - accuracy: 0.7571 - val_loss: 1.0363 - val_accuracy: 0.7000\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.8677 - accuracy: 0.7571 - val_loss: 1.0311 - val_accuracy: 0.7000\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8622 - accuracy: 0.7857 - val_loss: 1.0258 - val_accuracy: 0.7000\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8569 - accuracy: 0.7857 - val_loss: 1.0207 - val_accuracy: 0.7000\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8510 - accuracy: 0.7857 - val_loss: 1.0157 - val_accuracy: 0.7000\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8461 - accuracy: 0.7857 - val_loss: 1.0104 - val_accuracy: 0.7000\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8406 - accuracy: 0.7857 - val_loss: 1.0049 - val_accuracy: 0.7000\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8351 - accuracy: 0.7857 - val_loss: 0.9997 - val_accuracy: 0.7000\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8303 - accuracy: 0.7857 - val_loss: 0.9948 - val_accuracy: 0.7000\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8243 - accuracy: 0.7857 - val_loss: 0.9902 - val_accuracy: 0.7000\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8189 - accuracy: 0.7857 - val_loss: 0.9862 - val_accuracy: 0.7333\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.8133 - accuracy: 0.8000 - val_loss: 0.9821 - val_accuracy: 0.7333\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.8078 - accuracy: 0.8000 - val_loss: 0.9781 - val_accuracy: 0.7333\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.8027 - accuracy: 0.8000 - val_loss: 0.9745 - val_accuracy: 0.7333\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7973 - accuracy: 0.8000 - val_loss: 0.9703 - val_accuracy: 0.7333\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.7919 - accuracy: 0.8000 - val_loss: 0.9668 - val_accuracy: 0.7333\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7870 - accuracy: 0.8000 - val_loss: 0.9632 - val_accuracy: 0.7333\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7821 - accuracy: 0.8000 - val_loss: 0.9595 - val_accuracy: 0.7333\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7773 - accuracy: 0.8000 - val_loss: 0.9556 - val_accuracy: 0.7333\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7726 - accuracy: 0.8000 - val_loss: 0.9517 - val_accuracy: 0.7333\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7679 - accuracy: 0.8000 - val_loss: 0.9476 - val_accuracy: 0.7333\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7634 - accuracy: 0.8000 - val_loss: 0.9433 - val_accuracy: 0.7333\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7591 - accuracy: 0.8000 - val_loss: 0.9386 - val_accuracy: 0.7333\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7546 - accuracy: 0.8000 - val_loss: 0.9339 - val_accuracy: 0.7333\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7504 - accuracy: 0.8000 - val_loss: 0.9296 - val_accuracy: 0.7333\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7461 - accuracy: 0.8000 - val_loss: 0.9260 - val_accuracy: 0.7333\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7418 - accuracy: 0.8000 - val_loss: 0.9226 - val_accuracy: 0.7333\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7377 - accuracy: 0.8000 - val_loss: 0.9196 - val_accuracy: 0.7333\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.7335 - accuracy: 0.8000 - val_loss: 0.9164 - val_accuracy: 0.7333\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7293 - accuracy: 0.8000 - val_loss: 0.9126 - val_accuracy: 0.7667\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7250 - accuracy: 0.8143 - val_loss: 0.9089 - val_accuracy: 0.7667\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7210 - accuracy: 0.8143 - val_loss: 0.9053 - val_accuracy: 0.7667\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.7168 - accuracy: 0.8143 - val_loss: 0.9020 - val_accuracy: 0.7667\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.7130 - accuracy: 0.8143 - val_loss: 0.8986 - val_accuracy: 0.7667\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7091 - accuracy: 0.8143 - val_loss: 0.8950 - val_accuracy: 0.7667\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7049 - accuracy: 0.8143 - val_loss: 0.8906 - val_accuracy: 0.7667\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.7013 - accuracy: 0.8143 - val_loss: 0.8863 - val_accuracy: 0.7667\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6978 - accuracy: 0.8143 - val_loss: 0.8818 - val_accuracy: 0.7667\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6939 - accuracy: 0.8143 - val_loss: 0.8775 - val_accuracy: 0.7667\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6904 - accuracy: 0.8143 - val_loss: 0.8727 - val_accuracy: 0.8000\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6865 - accuracy: 0.8429 - val_loss: 0.8683 - val_accuracy: 0.8333\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6827 - accuracy: 0.8429 - val_loss: 0.8637 - val_accuracy: 0.8333\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6789 - accuracy: 0.8429 - val_loss: 0.8594 - val_accuracy: 0.8333\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.6745 - accuracy: 0.8429 - val_loss: 0.8554 - val_accuracy: 0.8333\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6709 - accuracy: 0.8429 - val_loss: 0.8517 - val_accuracy: 0.8333\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.6670 - accuracy: 0.8286 - val_loss: 0.8479 - val_accuracy: 0.8000\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6628 - accuracy: 0.8286 - val_loss: 0.8437 - val_accuracy: 0.8333\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.6591 - accuracy: 0.8429 - val_loss: 0.8400 - val_accuracy: 0.8333\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6553 - accuracy: 0.8429 - val_loss: 0.8363 - val_accuracy: 0.8333\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6516 - accuracy: 0.8429 - val_loss: 0.8325 - val_accuracy: 0.8333\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.6478 - accuracy: 0.8429 - val_loss: 0.8282 - val_accuracy: 0.8333\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6445 - accuracy: 0.8429 - val_loss: 0.8242 - val_accuracy: 0.8333\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6407 - accuracy: 0.8429 - val_loss: 0.8208 - val_accuracy: 0.8333\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6374 - accuracy: 0.8429 - val_loss: 0.8173 - val_accuracy: 0.8333\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6340 - accuracy: 0.8429 - val_loss: 0.8132 - val_accuracy: 0.8333\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6308 - accuracy: 0.8429 - val_loss: 0.8091 - val_accuracy: 0.8333\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6275 - accuracy: 0.8429 - val_loss: 0.8058 - val_accuracy: 0.8333\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6246 - accuracy: 0.8429 - val_loss: 0.8026 - val_accuracy: 0.8333\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.6211 - accuracy: 0.8429 - val_loss: 0.7988 - val_accuracy: 0.8333\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6180 - accuracy: 0.8429 - val_loss: 0.7949 - val_accuracy: 0.8333\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.6145 - accuracy: 0.8429 - val_loss: 0.7913 - val_accuracy: 0.8333\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.6111 - accuracy: 0.8429 - val_loss: 0.7878 - val_accuracy: 0.8333\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6081 - accuracy: 0.8429 - val_loss: 0.7842 - val_accuracy: 0.8333\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.6047 - accuracy: 0.8429 - val_loss: 0.7803 - val_accuracy: 0.8333\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.6014 - accuracy: 0.8429 - val_loss: 0.7767 - val_accuracy: 0.8333\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5984 - accuracy: 0.8429 - val_loss: 0.7728 - val_accuracy: 0.8333\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5953 - accuracy: 0.8429 - val_loss: 0.7692 - val_accuracy: 0.8333\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5921 - accuracy: 0.8429 - val_loss: 0.7655 - val_accuracy: 0.8333\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5889 - accuracy: 0.8429 - val_loss: 0.7613 - val_accuracy: 0.8333\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5857 - accuracy: 0.8429 - val_loss: 0.7569 - val_accuracy: 0.8333\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5827 - accuracy: 0.8429 - val_loss: 0.7527 - val_accuracy: 0.8333\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5795 - accuracy: 0.8429 - val_loss: 0.7489 - val_accuracy: 0.8333\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5763 - accuracy: 0.8714 - val_loss: 0.7454 - val_accuracy: 0.8333\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5734 - accuracy: 0.8714 - val_loss: 0.7418 - val_accuracy: 0.8333\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5706 - accuracy: 0.8714 - val_loss: 0.7384 - val_accuracy: 0.8333\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5677 - accuracy: 0.8714 - val_loss: 0.7349 - val_accuracy: 0.8333\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5648 - accuracy: 0.8714 - val_loss: 0.7315 - val_accuracy: 0.8333\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5620 - accuracy: 0.8714 - val_loss: 0.7283 - val_accuracy: 0.8333\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5591 - accuracy: 0.8714 - val_loss: 0.7250 - val_accuracy: 0.8333\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5561 - accuracy: 0.8714 - val_loss: 0.7219 - val_accuracy: 0.8333\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5535 - accuracy: 0.8714 - val_loss: 0.7183 - val_accuracy: 0.8333\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5504 - accuracy: 0.8714 - val_loss: 0.7150 - val_accuracy: 0.8333\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5476 - accuracy: 0.8714 - val_loss: 0.7114 - val_accuracy: 0.8333\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5446 - accuracy: 0.8714 - val_loss: 0.7079 - val_accuracy: 0.8333\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5420 - accuracy: 0.8714 - val_loss: 0.7044 - val_accuracy: 0.8333\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5389 - accuracy: 0.8714 - val_loss: 0.7012 - val_accuracy: 0.8333\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5361 - accuracy: 0.8714 - val_loss: 0.6979 - val_accuracy: 0.8333\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5332 - accuracy: 0.8714 - val_loss: 0.6945 - val_accuracy: 0.8333\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.5305 - accuracy: 0.8714 - val_loss: 0.6910 - val_accuracy: 0.8333\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.5277 - accuracy: 0.8714 - val_loss: 0.6873 - val_accuracy: 0.8333\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 0.5250 - accuracy: 0.8714 - val_loss: 0.6839 - val_accuracy: 0.8333\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5217 - accuracy: 0.8714 - val_loss: 0.6807 - val_accuracy: 0.8333\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.5188 - accuracy: 0.8714 - val_loss: 0.6778 - val_accuracy: 0.8333\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5156 - accuracy: 0.8714 - val_loss: 0.6751 - val_accuracy: 0.8333\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5123 - accuracy: 0.8714 - val_loss: 0.6727 - val_accuracy: 0.8333\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.5085 - accuracy: 0.8714 - val_loss: 0.6701 - val_accuracy: 0.8333\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.5044 - accuracy: 0.8714 - val_loss: 0.6670 - val_accuracy: 0.8333\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4999 - accuracy: 0.8714 - val_loss: 0.6641 - val_accuracy: 0.8333\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4961 - accuracy: 0.8714 - val_loss: 0.6614 - val_accuracy: 0.8333\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4927 - accuracy: 0.8714 - val_loss: 0.6590 - val_accuracy: 0.8333\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4894 - accuracy: 0.8714 - val_loss: 0.6569 - val_accuracy: 0.8333\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4867 - accuracy: 0.8714 - val_loss: 0.6545 - val_accuracy: 0.8333\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4840 - accuracy: 0.8714 - val_loss: 0.6519 - val_accuracy: 0.8333\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4813 - accuracy: 0.8714 - val_loss: 0.6494 - val_accuracy: 0.8333\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4791 - accuracy: 0.8714 - val_loss: 0.6470 - val_accuracy: 0.8333\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4765 - accuracy: 0.8714 - val_loss: 0.6441 - val_accuracy: 0.8333\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4741 - accuracy: 0.8714 - val_loss: 0.6412 - val_accuracy: 0.8333\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.4717 - accuracy: 0.8714 - val_loss: 0.6386 - val_accuracy: 0.8333\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4694 - accuracy: 0.8714 - val_loss: 0.6362 - val_accuracy: 0.8333\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4670 - accuracy: 0.8857 - val_loss: 0.6337 - val_accuracy: 0.8333\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4647 - accuracy: 0.9000 - val_loss: 0.6305 - val_accuracy: 0.8333\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4624 - accuracy: 0.9000 - val_loss: 0.6270 - val_accuracy: 0.8333\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4601 - accuracy: 0.9000 - val_loss: 0.6237 - val_accuracy: 0.8333\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4579 - accuracy: 0.9000 - val_loss: 0.6203 - val_accuracy: 0.8333\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4558 - accuracy: 0.9000 - val_loss: 0.6173 - val_accuracy: 0.8333\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4538 - accuracy: 0.9000 - val_loss: 0.6148 - val_accuracy: 0.8333\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4515 - accuracy: 0.9000 - val_loss: 0.6127 - val_accuracy: 0.8667\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4493 - accuracy: 0.9143 - val_loss: 0.6106 - val_accuracy: 0.8667\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4471 - accuracy: 0.9143 - val_loss: 0.6084 - val_accuracy: 0.8667\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4446 - accuracy: 0.9143 - val_loss: 0.6062 - val_accuracy: 0.8667\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4424 - accuracy: 0.9143 - val_loss: 0.6046 - val_accuracy: 0.8667\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4402 - accuracy: 0.9143 - val_loss: 0.6031 - val_accuracy: 0.8667\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4381 - accuracy: 0.9143 - val_loss: 0.6012 - val_accuracy: 0.8667\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4359 - accuracy: 0.9143 - val_loss: 0.5989 - val_accuracy: 0.8667\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.4338 - accuracy: 0.9143 - val_loss: 0.5971 - val_accuracy: 0.8667\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4319 - accuracy: 0.9143 - val_loss: 0.5951 - val_accuracy: 0.8667\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4298 - accuracy: 0.9143 - val_loss: 0.5930 - val_accuracy: 0.8667\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4280 - accuracy: 0.9143 - val_loss: 0.5913 - val_accuracy: 0.8667\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.4260 - accuracy: 0.9143 - val_loss: 0.5897 - val_accuracy: 0.8667\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4240 - accuracy: 0.9143 - val_loss: 0.5884 - val_accuracy: 0.8667\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4221 - accuracy: 0.9143 - val_loss: 0.5870 - val_accuracy: 0.8667\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 0.4203 - accuracy: 0.9143 - val_loss: 0.5856 - val_accuracy: 0.8667\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4183 - accuracy: 0.9143 - val_loss: 0.5843 - val_accuracy: 0.8667\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.4166 - accuracy: 0.9143 - val_loss: 0.5823 - val_accuracy: 0.8667\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.4147 - accuracy: 0.9143 - val_loss: 0.5803 - val_accuracy: 0.8667\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4127 - accuracy: 0.9143 - val_loss: 0.5786 - val_accuracy: 0.8667\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4109 - accuracy: 0.9143 - val_loss: 0.5770 - val_accuracy: 0.8667\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4089 - accuracy: 0.9143 - val_loss: 0.5749 - val_accuracy: 0.8667\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4072 - accuracy: 0.9143 - val_loss: 0.5730 - val_accuracy: 0.8667\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.4053 - accuracy: 0.9143 - val_loss: 0.5710 - val_accuracy: 0.8667\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4035 - accuracy: 0.9143 - val_loss: 0.5691 - val_accuracy: 0.8667\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.4017 - accuracy: 0.9143 - val_loss: 0.5676 - val_accuracy: 0.8667\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.4000 - accuracy: 0.9143 - val_loss: 0.5660 - val_accuracy: 0.8667\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3985 - accuracy: 0.9143 - val_loss: 0.5639 - val_accuracy: 0.8667\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3966 - accuracy: 0.9143 - val_loss: 0.5621 - val_accuracy: 0.8667\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3950 - accuracy: 0.9143 - val_loss: 0.5603 - val_accuracy: 0.8667\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3932 - accuracy: 0.9143 - val_loss: 0.5586 - val_accuracy: 0.8667\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 0.3914 - accuracy: 0.9143 - val_loss: 0.5564 - val_accuracy: 0.8667\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3897 - accuracy: 0.9143 - val_loss: 0.5540 - val_accuracy: 0.8667\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3879 - accuracy: 0.9143 - val_loss: 0.5519 - val_accuracy: 0.8667\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3863 - accuracy: 0.9143 - val_loss: 0.5503 - val_accuracy: 0.8667\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3845 - accuracy: 0.9143 - val_loss: 0.5489 - val_accuracy: 0.8667\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3828 - accuracy: 0.9143 - val_loss: 0.5472 - val_accuracy: 0.8667\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3808 - accuracy: 0.9143 - val_loss: 0.5452 - val_accuracy: 0.8667\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3793 - accuracy: 0.9143 - val_loss: 0.5429 - val_accuracy: 0.8667\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3777 - accuracy: 0.9143 - val_loss: 0.5408 - val_accuracy: 0.8667\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3761 - accuracy: 0.9143 - val_loss: 0.5388 - val_accuracy: 0.8667\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3743 - accuracy: 0.9143 - val_loss: 0.5371 - val_accuracy: 0.8667\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 0.3728 - accuracy: 0.9143 - val_loss: 0.5354 - val_accuracy: 0.9000\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3714 - accuracy: 0.9286 - val_loss: 0.5335 - val_accuracy: 0.9000\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3698 - accuracy: 0.9286 - val_loss: 0.5312 - val_accuracy: 0.9000\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 0.3682 - accuracy: 0.9286 - val_loss: 0.5290 - val_accuracy: 0.9333\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3666 - accuracy: 0.9429 - val_loss: 0.5267 - val_accuracy: 0.9333\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3650 - accuracy: 0.9429 - val_loss: 0.5250 - val_accuracy: 0.9333\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3635 - accuracy: 0.9429 - val_loss: 0.5236 - val_accuracy: 0.9333\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3618 - accuracy: 0.9429 - val_loss: 0.5220 - val_accuracy: 0.9333\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3604 - accuracy: 0.9429 - val_loss: 0.5202 - val_accuracy: 0.9333\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3588 - accuracy: 0.9429 - val_loss: 0.5186 - val_accuracy: 0.9333\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3572 - accuracy: 0.9429 - val_loss: 0.5171 - val_accuracy: 0.9333\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3556 - accuracy: 0.9429 - val_loss: 0.5157 - val_accuracy: 0.9333\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3543 - accuracy: 0.9429 - val_loss: 0.5139 - val_accuracy: 0.9333\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.3529 - accuracy: 0.9429 - val_loss: 0.5118 - val_accuracy: 0.9333\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3513 - accuracy: 0.9429 - val_loss: 0.5091 - val_accuracy: 0.9333\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3499 - accuracy: 0.9429 - val_loss: 0.5057 - val_accuracy: 0.9333\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3484 - accuracy: 0.9429 - val_loss: 0.5029 - val_accuracy: 0.9333\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3471 - accuracy: 0.9429 - val_loss: 0.5008 - val_accuracy: 0.9333\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3457 - accuracy: 0.9429 - val_loss: 0.4992 - val_accuracy: 0.9333\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 0.3444 - accuracy: 0.9429 - val_loss: 0.4976 - val_accuracy: 0.9333\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3431 - accuracy: 0.9429 - val_loss: 0.4961 - val_accuracy: 0.9333\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3417 - accuracy: 0.9429 - val_loss: 0.4947 - val_accuracy: 0.9333\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3403 - accuracy: 0.9429 - val_loss: 0.4933 - val_accuracy: 0.9333\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.3390 - accuracy: 0.9429 - val_loss: 0.4918 - val_accuracy: 0.9333\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.3376 - accuracy: 0.9429 - val_loss: 0.4897 - val_accuracy: 0.9333\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=300, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.33646926283836365\n",
      "Train acc: 0.9428571462631226\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_train, y_train, verbose=0)\n",
    "print(\"Train loss:\", loss)\n",
    "print(\"Train acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.48965418338775635\n",
      "Test acc: 0.9333333373069763\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", loss)\n",
    "print(\"Test acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"final_model_pca.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e24f5c8f47ce628df06e6a418f439355aaed4f63445fc5001ab64130bd080cd8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.cargas_eletricas': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
